{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install datasets evaluate transformers[sentencepiece]\n",
    "# ! pip install accelerate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is a great [MASK].\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> This is a great deal.'\n",
      "'>>> This is a great success.'\n",
      "'>>> This is a great adventure.'\n",
      "'>>> This is a great idea.'\n",
      "'>>> This is a great feat.'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "token_logits = model(**inputs).logits\n",
    "\n",
    "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "\n",
    "for token in top_5_tokens:\n",
    "    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['Diagnosis You may not know you have atrial fibrillation AFib', 'The condition may be found when a health checkup is done for another reason', 'This quick and painless test measures the electrical activity of the heart']\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataset_gl10_lt15.txt\", 'r', encoding='utf-8') as f:\n",
    "    sent = [line.strip() for line in f]\n",
    "\n",
    "print(type(sent))\n",
    "print(sent[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 35158\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 8790\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# from datasets import Dataset\n",
    "# from datasets import DatasetDict\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train, val, _, _ = train_test_split(sent, sent, train_size=0.8, random_state=1)\n",
    "\n",
    "# train = [{\"text\": sentence} for sentence in train]\n",
    "# train = Dataset.from_list(train)\n",
    "\n",
    "# val = [{\"text\": sentence} for sentence in val]\n",
    "# val = Dataset.from_list(val)\n",
    "\n",
    "# dataset = DatasetDict({\n",
    "#     \"train\": train,\n",
    "#     \"validation\": val\n",
    "# })\n",
    "\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 43948\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from datasets import DatasetDict\n",
    "\n",
    "train = train = [{\"text\": sentence} for sentence in sent]\n",
    "train = Dataset.from_list(train)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train,\n",
    "    # \"validation\": val\n",
    "})\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Does any type of activity ease the pain or worsen it'\n",
      ">>> If pericardial effusion signs and symptoms do occur, they might include'\n",
      ">>> If you miss a dose of levothyroxine, take two pills the next day'\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"].shuffle(seed=42).select(range(3))\n",
    "\n",
    "for row in sample:\n",
    "    print(f\">>> {row['text']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833f1711b7f6405c9afab8033dba4058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/43948 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 43948\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"text\"])\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result\n",
    "\n",
    "\n",
    "# Use batched=True to activate fast multithreading!\n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=[\"text\"]\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> sentence 0 length: 16'\n",
      "'>>> sentence 1 length: 17'\n",
      "'>>> sentence 2 length: 15'\n"
     ]
    }
   ],
   "source": [
    "tokenized_samples = tokenized_datasets[\"train\"][:3]\n",
    "\n",
    "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
    "    print(f\"'>>> sentence {idx} length: {len(sample)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Concatenated sentences length: 48'\n"
     ]
    }
   ],
   "source": [
    "concatenated_examples = {\n",
    "    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n",
    "}\n",
    "total_length = len(concatenated_examples[\"input_ids\"])\n",
    "print(f\"'>>> Concatenated sentences length: {total_length}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Chunk length: 48'\n"
     ]
    }
   ],
   "source": [
    "chunks = {\n",
    "    k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "    for k, t in concatenated_examples.items()\n",
    "}\n",
    "\n",
    "for chunk in chunks[\"input_ids\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    # Compute length of concatenated texts\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the last chunk if it's smaller than chunk_size\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    # Split by chunks of max_len\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # Create a new labels column\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3966d83c3caa4ca4b268867051b8c2da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/43948 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 5772\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'device shows how the heart is beating while you do your daily activities [SEP] [CLS] it may be used to see how often you have an afib episode [SEP] [CLS] for example, you may need one if you ve had an unexplained stroke echocardiogram [SEP] [CLS] sound waves are used to create images of the beating heart [SEP] [CLS] this test can show how blood flows through the heart and heart valves [SEP] [CLS] a chest x ray shows the condition of the lungs and heart [SEP] [CLS] more information atrial fibrillation care at echocardiogramelectrocardiogram ecg or ekg ep studyholter monitorx rays'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [CLS] diagnosis you may not know you have atrial [MASK]brillation afib [SEP] [CLS] [MASK] [MASK] [MASK] [MASK] found when a health checkup is done for another reason [SEP] [CLS] this quick and painless test [MASK] the [MASK] activity of the heart [SEP] [CLS] sticky patches called electrodes are placed on the chestologist sometimes the [MASK] and legs [SEP] [CLS] wires connect the electrodes to a computer, which [MASK] or displays [MASK] test results [SEP] [CLS] it s worn [MASK] a day [MASK] two while you do your regular activities [SEP] [CLS] some [MASK] automatically record when an irregular [MASK] rhythm is detected [SEP] [CLS] [MASK] device records [MASK] heartbeat continuously for up to three years [SEP] [CLS] the'\n",
      ">>> device shows how the heart [MASK] beating while you do your daily activities [SEP] [CLS] [MASK] may [MASK] used [MASK] see how often you [MASK] an afib episode [SEP] [CLS] for example, you may need one if you ve had an unexplained stroke echocard [MASK]gram [SEP] [CLS] sound waves are used to create images of [MASK] beating heart [SEP] [CLS] this test [MASK] show how [MASK] flows through [MASK] heart and heart valves [SEP] [CLS] a chest [MASK] ray shows the condition of adelaide lungs and heart [SEP] [CLS] more information atrial fibrillation jeremy at echocardiogramelectrocardiogram ecg or ek [MASK] ep studyholter monitorx rays'\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "for sample in samples:\n",
    "    _ = sample.pop(\"word_ids\")\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\">>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "from transformers import default_data_collator\n",
    "\n",
    "wwm_probability = 0.2\n",
    "\n",
    "\n",
    "def whole_word_masking_data_collator(features):\n",
    "    for feature in features:\n",
    "        word_ids = feature.pop(\"word_ids\")\n",
    "\n",
    "        # Create a map between words and corresponding token indices\n",
    "        mapping = collections.defaultdict(list)\n",
    "        current_word_index = -1\n",
    "        current_word = None\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id is not None:\n",
    "                if word_id != current_word:\n",
    "                    current_word = word_id\n",
    "                    current_word_index += 1\n",
    "                mapping[current_word_index].append(idx)\n",
    "\n",
    "        # Randomly mask words\n",
    "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
    "        input_ids = feature[\"input_ids\"]\n",
    "        labels = feature[\"labels\"]\n",
    "        new_labels = [-100] * len(labels)\n",
    "        for word_id in np.where(mask)[0]:\n",
    "            word_id = word_id.item()\n",
    "            for idx in mapping[word_id]:\n",
    "                new_labels[idx] = labels[idx]\n",
    "                input_ids[idx] = tokenizer.mask_token_id\n",
    "        feature[\"labels\"] = new_labels\n",
    "\n",
    "    return default_data_collator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [CLS] diagnosis [MASK] may not know you have [MASK] [MASK] fibrillation afib [SEP] [CLS] the [MASK] [MASK] be found when a health checkup is done for another reason [SEP] [CLS] this quick and painless test measures the electrical activity [MASK] [MASK] [MASK] [SEP] [CLS] sticky patches called electrodes are placed on [MASK] chest and sometimes the arms and [MASK] [SEP] [CLS] wires [MASK] [MASK] electrodes [MASK] a computer, which prints or [MASK] the test results [SEP] [CLS] it [MASK] worn [MASK] a day or [MASK] while you do your regular activities [SEP] [CLS] [MASK] devices automatically record when an irregular heart [MASK] is detected [SEP] [CLS] this device records the heartbeat continuously for up to three years [SEP] [CLS] the\n",
      ">>> device [MASK] how the heart is beating while you [MASK] [MASK] daily [MASK] [SEP] [CLS] [MASK] may [MASK] used [MASK] [MASK] how often you have [MASK] [MASK] [MASK] episode [SEP] [CLS] for example, you may [MASK] one if you ve [MASK] [MASK] unexplained stroke echocardiogram [SEP] [CLS] sound waves are used to create [MASK] of the beating [MASK] [SEP] [CLS] this test can show how blood flows through the heart [MASK] heart valves [SEP] [CLS] a chest x ray shows the condition of the lungs [MASK] heart [SEP] [CLS] more information [MASK] [MASK] [MASK] [MASK] [MASK] care at [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ecg or ekg ep [MASK] [MASK] [MASK] [MASK] [MASK] rays\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "batch = whole_word_masking_data_collator(samples)\n",
    "\n",
    "for chunk in batch[\"input_ids\"]:\n",
    "    print(f\">>> {tokenizer.decode(chunk)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 5194\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 578\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = 0.9\n",
    "test_size = 0.1\n",
    "\n",
    "downsampled_dataset = lm_datasets[\"train\"].train_test_split(\n",
    "    train_size=train_size, test_size=test_size, seed=42\n",
    ")\n",
    "downsampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 64\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(downsampled_dataset[\"train\"]) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned\",\n",
    "    # overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=downsampled_dataset[\"train\"],\n",
    "    eval_dataset=downsampled_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90733928cd144e7850f956637cf6a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652ccd69587b489685ab60fb91405ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0009605884552, 'eval_runtime': 2.3043, 'eval_samples_per_second': 250.835, 'eval_steps_per_second': 4.34, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a22f6f8e1c74296be8cbb2551e1614f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9535224437713623, 'eval_runtime': 1.9858, 'eval_samples_per_second': 291.072, 'eval_steps_per_second': 5.036, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1e79a1b6e84f2b80646ed12916e771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.937943935394287, 'eval_runtime': 2.0143, 'eval_samples_per_second': 286.952, 'eval_steps_per_second': 4.965, 'epoch': 3.0}\n",
      "{'train_runtime': 293.115, 'train_samples_per_second': 53.16, 'train_steps_per_second': 0.839, 'train_loss': 2.0671412770341084, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=246, training_loss=2.0671412770341084, metrics={'train_runtime': 293.115, 'train_samples_per_second': 53.16, 'train_steps_per_second': 0.839, 'train_loss': 2.0671412770341084, 'epoch': 3.0})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "mask_filler = pipeline(\n",
    "    \"fill-mask\", model=model, tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "diagnosis you may not know you have atrial fibrillation afib\n",
      "-----\n",
      "diagnosis you may not know you have atrial fibrillation afib\n",
      "-----\n",
      "diagnosis you may not know you have atrial fibrillation afib\n",
      "-----\n",
      "diagnosis you may not know you have atrial fibrillation afib\n",
      "-----\n",
      "diagnosis you may not know you have a fibrillation afib\n",
      "-----\n",
      "diagnosis you may not know you have atrial valve afib\n"
     ]
    }
   ],
   "source": [
    "# Diagnosis You may not know you have atrial fibrillation AFib\n",
    "test_sentences =[\"Diagnosis [MASK] may not know you have atrial fibrillation AFib\",\n",
    "                 \"Diagnosis You [MASK] not know you have atrial fibrillation AFib\",\n",
    "                 \"Diagnosis You may not [MASK] you have atrial fibrillation AFib\",\n",
    "                 \"Diagnosis You may not know you [MASK] atrial fibrillation AFib\",\n",
    "                 \"Diagnosis You may not know you have [MASK] fibrillation AFib\",\n",
    "                 \"Diagnosis You may not know you have atrial [MASK] AFib\"]\n",
    "\n",
    "for text in test_sentences:\n",
    "    preds = mask_filler(text)\n",
    "    print(\"-----\")\n",
    "    # for pred in preds:\n",
    "    #     print(f\"> {pred['sequence']}\")\n",
    "    print(preds[0]['sequence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: \t Cardioversion therapyIf atrial fibrillation symptoms are bothersome or if this is the first AFib episode, a doctor may try to reset the heart rhythm using a procedure called cardioversion.\n",
      "\n",
      "[{'score': 0.6329159140586853, 'token': 3460, 'token_str': 'doctor', 'sequence': '[CLS] cardioversion therapyif atrial fibrillation symptoms are bothersome or if this is the first afib episode, a doctor may try to reset the [MASK] rhythm using a procedure called cardioversion. [SEP]'}, {'score': 0.09803592413663864, 'token': 9431, 'token_str': 'surgeon', 'sequence': '[CLS] cardioversion therapyif atrial fibrillation symptoms are bothersome or if this is the first afib episode, a surgeon may try to reset the [MASK] rhythm using a procedure called cardioversion. [SEP]'}, {'score': 0.06754632294178009, 'token': 2711, 'token_str': 'person', 'sequence': '[CLS] cardioversion therapyif atrial fibrillation symptoms are bothersome or if this is the first afib episode, a person may try to reset the [MASK] rhythm using a procedure called cardioversion. [SEP]'}, {'score': 0.04999784007668495, 'token': 19294, 'token_str': 'therapist', 'sequence': '[CLS] cardioversion therapyif atrial fibrillation symptoms are bothersome or if this is the first afib episode, a therapist may try to reset the [MASK] rhythm using a procedure called cardioversion. [SEP]'}, {'score': 0.021638920530676842, 'token': 6821, 'token_str': 'nurse', 'sequence': '[CLS] cardioversion therapyif atrial fibrillation symptoms are bothersome or if this is the first afib episode, a nurse may try to reset the [MASK] rhythm using a procedure called cardioversion. [SEP]'}]\n",
      "[{'score': 0.8943960070610046, 'token': 2540, 'token_str': 'heart', 'sequence': '[CLS] cardioversion therapyif atrial fibrillation symptoms are bothersome or if this is the first afib episode, a [MASK] may try to reset the heart rhythm using a procedure called cardioversion. [SEP]'}, {'score': 0.03920238837599754, 'token': 2668, 'token_str': 'blood', 'sequence': '[CLS] cardioversion therapyif atrial fibrillation symptoms are bothersome or if this is the first afib episode, a [MASK] may try to reset the blood rhythm using a procedure called cardioversion. [SEP]'}, {'score': 0.008477674797177315, 'token': 6348, 'token_str': 'rhythm', 'sequence': '[CLS] cardioversion therapyif atrial fibrillation symptoms are bothersome or if this is the first afib episode, a [MASK] may try to reset the rhythm rhythm using a procedure called cardioversion. [SEP]'}, {'score': 0.00671085249632597, 'token': 12251, 'token_str': 'heartbeat', 'sequence': '[CLS] cardioversion therapyif atrial fibrillation symptoms are bothersome or if this is the first afib episode, a [MASK] may try to reset the heartbeat rhythm using a procedure called cardioversion. [SEP]'}, {'score': 0.004144566133618355, 'token': 2303, 'token_str': 'body', 'sequence': '[CLS] cardioversion therapyif atrial fibrillation symptoms are bothersome or if this is the first afib episode, a [MASK] may try to reset the body rhythm using a procedure called cardioversion. [SEP]'}]\n"
     ]
    }
   ],
   "source": [
    "text = \"Cardioversion therapyIf atrial fibrillation symptoms are bothersome or if this is the first AFib episode, a doctor may try to reset the heart rhythm using a procedure called cardioversion.\"\n",
    "masked = \"Cardioversion therapyIf atrial fibrillation symptoms are bothersome or if this is the first AFib episode, a [MASK] may try to reset the [MASK] rhythm using a procedure called cardioversion.\"\n",
    "\n",
    "preds = mask_filler(masked)\n",
    "\n",
    "\n",
    "print(f\"Original text: \\t {text}\\n\")\n",
    "\n",
    "for pred in preds:\n",
    "    # print(f\"\\t >{pred['sequence']}\")\n",
    "    print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
